"""
LangGraph ReAct Coordinator Agent with A2A protocol integration and streaming capabilities.
"""
import asyncio
import json
import time
import os
from typing import TypedDict, Annotated, Sequence, AsyncGenerator, Optional, Dict, Any, List
from datetime import datetime
from langgraph.graph import StateGraph, END
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage
from langchain_core.tools import tool
from langchain.agents import create_react_agent
from langchain.prompts import PromptTemplate
from search_agent import SearchAgent
from summarizer_agent import SummarizerAgent
from verifier_agent import VerifierAgent
from models import IntelligenceReport
from a2a_protocol import A2AProtocol, A2AMessage, MessageType, AgentRole
import operator

from dotenv import load_dotenv
load_dotenv()

# Simple guardrails for input validation
class SimpleGuardrails:
    """Simple input validation without external dependencies."""
    
    @staticmethod
    def validate_query(text: str) -> bool:
        """Basic query validation."""
        # Check for basic harmful patterns
        harmful_patterns = [
            'hack', 'exploit', 'malware', 'virus', 'attack',
            'bomb', 'kill', 'murder', 'suicide', 'harm'
        ]
        
        text_lower = text.lower()
        for pattern in harmful_patterns:
            if pattern in text_lower:
                return False
        
        # Check if query is reasonable length
        if len(text) > 500:  # Too long
            return False
            
        return True



class AgentState(TypedDict):
    """State for the LangGraph ReAct workflow."""
    messages: Annotated[Sequence[BaseMessage], "The list of messages in the conversation"]
    query: str
    results: Dict[str, Any]
    memory_key: str
    thread_id: str
    stream_data: List[Dict[str, Any]]
    step_counter: Dict[str, int]  # Track completed steps


class LangGraphCoordinatorAgent:
    """LangGraph ReAct Coordinator Agent with A2A protocol integration."""
    
    def __init__(self, hf_token: str = None, use_a2a: bool = True):
        # Initialize sub-agents
        self.search_agent = SearchAgent()
        self.summarizer_agent = SummarizerAgent(hf_token=hf_token)
        self.verifier_agent = VerifierAgent()
        
        # Initialize HF model for ReAct reasoning
        self.hf_token = hf_token
        self.llm = self._init_reasoning_llm()
        
        # Initialize Guardrails for input validation
        self._init_guardrails()
        
        # Initialize A2A Protocol
        self.use_a2a = use_a2a
        if self.use_a2a:
            self.a2a_protocol = A2AProtocol()
            self._setup_a2a_handlers()
            print("üîó A2A Protocol initialized for agent communication")
        
        # Initialize in-memory storage (no database)
        self.memory_store = {}
        self.conversation_history = {}
        self.tools = self._create_tools()
        self.graph = self._create_graph()
        
        # Cache for avoiding repeated queries
        self.cache = {}
        
        print("ü§ñ LangGraph Coordinator Agent initialized with A2A protocol integration")
    
    def _setup_a2a_handlers(self):
        """Setup A2A protocol handlers for agent communication."""
        try:
            # Register this coordinator with A2A protocol
            self.a2a_protocol.register_agent(AgentRole.COORDINATOR, self._handle_a2a_message)
            self.a2a_protocol.register_agent(AgentRole.SEARCH, self._handle_search_message)
            self.a2a_protocol.register_agent(AgentRole.SUMMARIZER, self._handle_summarizer_message)
            self.a2a_protocol.register_agent(AgentRole.VERIFIER, self._handle_verifier_message)
            
            # Setup subscriptions
            self.a2a_protocol.subscribe(AgentRole.COORDINATOR, MessageType.RESPONSE)
            self.a2a_protocol.subscribe(AgentRole.COORDINATOR, MessageType.ERROR)
            self.a2a_protocol.subscribe(AgentRole.SEARCH, MessageType.REQUEST)
            self.a2a_protocol.subscribe(AgentRole.SUMMARIZER, MessageType.REQUEST)
            self.a2a_protocol.subscribe(AgentRole.VERIFIER, MessageType.REQUEST)
            
            print("üîó A2A protocol handlers configured")
        except Exception as e:
            print(f"‚ö†Ô∏è A2A setup failed: {e}")
    
    async def _handle_a2a_message(self, message: A2AMessage):
        """Handle A2A messages for coordinator."""
        try:
            if message.type == MessageType.RESPONSE:
                print(f"üì• A2A Response received from {message.sender.value}")
                # Process response based on sender
                await self._process_a2a_response(message)
            elif message.type == MessageType.ERROR:
                print(f"‚ùå A2A Error from {message.sender.value}: {message.payload.get('error', 'Unknown error')}")
        except Exception as e:
            print(f"‚ùå Error handling A2A message: {e}")
    
    async def _handle_search_message(self, message: A2AMessage):
        """Handle search requests via A2A."""
        if message.type == MessageType.REQUEST:
            query = message.payload.get("query", "")
            enhanced_query = self._enhance_search_query(query)
            
            try:
                search_results = self.search_agent.search(enhanced_query, max_results=5)
                
                response = A2AMessage(
                    id=f"search_response_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}",
                    type=MessageType.RESPONSE,
                    sender=AgentRole.SEARCH,
                    receiver=AgentRole.COORDINATOR,
                    payload={"results": [{"url": r.url, "title": r.title, "snippet": r.snippet, "source": r.source} for r in search_results]},
                    timestamp=datetime.now().isoformat(),
                    correlation_id=message.id
                )
                
                await self.a2a_protocol.send_message(response)
                print(f"üîç A2A Search completed for: {enhanced_query}")
                
            except Exception as e:
                await self._send_a2a_error(message, str(e), AgentRole.SEARCH)
    
    async def _handle_summarizer_message(self, message: A2AMessage):
        """Handle summarizer requests via A2A."""
        if message.type == MessageType.REQUEST:
            search_results_data = message.payload.get("search_results", [])
            
            try:
                # Convert to JSON format for summarizer
                search_json = json.dumps({"status": "success", "results": search_results_data})
                updates = self.summarizer_agent.summarize_from_json(search_json, "product_update")
                
                response = A2AMessage(
                    id=f"summarizer_response_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}",
                    type=MessageType.RESPONSE,
                    sender=AgentRole.SUMMARIZER,
                    receiver=AgentRole.COORDINATOR,
                    payload={"updates": [update.dict() for update in updates] if updates else []},
                    timestamp=datetime.now().isoformat(),
                    correlation_id=message.id
                )
                
                await self.a2a_protocol.send_message(response)
                print(f"üìù A2A Summarization completed")
                
            except Exception as e:
                await self._send_a2a_error(message, str(e), AgentRole.SUMMARIZER)
    
    async def _handle_verifier_message(self, message: A2AMessage):
        """Handle verifier requests via A2A."""
        if message.type == MessageType.REQUEST:
            updates_data = message.payload.get("updates", [])
            
            try:
                # Convert to ProductUpdate objects
                from models import ProductUpdate
                updates = [ProductUpdate(**update) for update in updates_data if update]
                
                verified_updates = self.verifier_agent.verify(updates)
                
                response = A2AMessage(
                    id=f"verifier_response_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}",
                    type=MessageType.RESPONSE,
                    sender=AgentRole.VERIFIER,
                    receiver=AgentRole.COORDINATOR,
                    payload={"verified_updates": [update.dict() for update in verified_updates]},
                    timestamp=datetime.now().isoformat(),
                    correlation_id=message.id
                )
                
                await self.a2a_protocol.send_message(response)
                print(f"‚úÖ A2A Verification completed")
                
            except Exception as e:
                await self._send_a2a_error(message, str(e), AgentRole.VERIFIER)
    
    async def _send_a2a_error(self, original_message: A2AMessage, error: str, sender: AgentRole):
        """Send A2A error response."""
        error_message = A2AMessage(
            id=f"error_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}",
            type=MessageType.ERROR,
            sender=sender,
            receiver=original_message.sender,
            payload={"error": error, "original_message_id": original_message.id},
            timestamp=datetime.now().isoformat(),
            correlation_id=original_message.id
        )
        
        await self.a2a_protocol.send_message(error_message)
    
    async def _process_a2a_response(self, message: A2AMessage):
        """Process A2A responses and continue workflow."""
        # Store the response for later use
        correlation_id = message.correlation_id
        if not hasattr(self, 'a2a_responses'):
            self.a2a_responses = {}
        if correlation_id not in self.a2a_responses:
            self.a2a_responses[correlation_id] = {}
        
        self.a2a_responses[correlation_id][message.sender.value] = message.payload
    
    def _init_reasoning_llm(self):
        """Initialize reasoning LLM for ReAct decision making"""
        try:
            from langchain_groq import ChatGroq
            
            # Get Groq API key from .env file
            groq_api_key = os.getenv('GROQ_API_KEY')
            
            if groq_api_key:
                
                # Initialize ChatGroq with llama3-8b-8192 model
                self.reasoning_llm = ChatGroq(
                    model="llama3-8b-8192",
                    api_key=groq_api_key,
                    temperature=0.3,
                    max_tokens=500
                )
                print("‚úÖ Groq reasoning model loaded: llama3-8b-8192")
                self.use_groq_reasoning = True
                
            else:
                print("‚ö†Ô∏è No Groq API key found in .env file, using rule-based reasoning")
                self.use_groq_reasoning = False
                
        except Exception as e:
            print(f"‚ö†Ô∏è Groq model failed to load: {e}")
            print("Using rule-based reasoning")
            self.use_groq_reasoning = False
    
    def _init_guardrails(self):
        """Initialize simple guardrails for input validation"""
        self.guardrails = SimpleGuardrails()
        self.use_guardrails = True
        print("‚úÖ Simple Guardrails initialized for query validation")
    
    def _create_react_prompt_template(self) -> PromptTemplate:
        """Create ReAct prompt template for intelligent decision making"""
        template = """You are a ReAct (Reasoning + Acting) agent that helps users with competitive intelligence and product updates and also handle typos.

Current query: {query}

Available tools:
1. search_intelligence - Search for latest information about products/companies/technologies
2. summarize_content - Extract key product updates from search results  
3. verify_updates - Verify and validate the updates for accuracy

Instructions:
- For casual greetings (hi, hello, hey): Respond directly with a friendly greeting and explain your capabilities
- For product/company/technologies queries: Use tools to search, summarize, and verify information
- For specific questions about products: Use the search tool first, then summarize and verify

Think step by step:
1. Analyze the user's query
2. Decide if you should respond directly OR use tools
3. If using tools, choose the appropriate tool and provide arguments

Query: {query}

Decision: Should I respond directly or use tools?
Response:"""
        
        return PromptTemplate(
            input_variables=["query"],
            template=template
        )
    
    def _make_intelligent_decision(self, query: str, step_counter: dict) -> dict:
        """Use Groq LLM with prompt template to make ReAct decisions"""
        try:
            # Check if this is a greeting or casual query
            casual_queries = ["hi", "hello", "hey", "sup", "yo", "greetings"]
            if query.lower().strip() in casual_queries:
                return {
                    "action": "respond_directly",
                    "response": f"üëã Hello! I'm your chatbot. I can search for competitive intelligence, analyze product updates, and provide structured insights.\n\nWhat would you like to analyze today?",
                    "reasoning": "Casual greeting detected - respond directly with capabilities"
                }
            
            # Check for personal introductions (e.g., "i am yaswanth", "my name is john")
            introduction_patterns = [
                r"i am (\w+)",
                r"my name is (\w+)", 
                r"this is (\w+)",
                r"i'm (\w+)"
            ]
            
            for pattern in introduction_patterns:
                import re
                match = re.search(pattern, query.lower())
                if match:
                    name = match.group(1).title()
                    return {
                        "action": "respond_directly",
                        "response": f"Nice to meet you, {name}! üëã  I specialize in competitive intelligence and product analysis.\n\nI can help you with:\n‚Ä¢ Real-time product updates and features\n‚Ä¢ Technology news and announcements\n‚Ä¢ Competitive intelligence analysis\n‚Ä¢ Company and startup insights\n\nWhat would you like me to research for you today, {name}?",
                        "reasoning": f"Personal introduction detected for {name} - respond with personalized greeting"
                    }
            
            # Use Groq LLM for intelligent decision making
            if hasattr(self, 'use_groq_reasoning') and self.use_groq_reasoning and hasattr(self, 'reasoning_llm'):
                try:
                    # Create a decision prompt for the LLM
                    search_count = step_counter.get("search", 0)
                    summarize_count = step_counter.get("summarize", 0) 
                    verify_count = step_counter.get("verify", 0)
                    
                    decision_prompt = f"""
You are a ReAct agent. Based on the workflow state, choose the next action.

Query: "{query}"
Progress: search={search_count}, summarize={summarize_count}, verify={verify_count}

Rules:
- If search=0: Choose "search_intelligence"
- If search>0 AND summarize=0: Choose "summarize_content"  
- If summarize>0 AND verify=0: Choose "verify_updates"
- If all>0: Choose "complete"

Next action (one word only):"""

                    from langchain_core.messages import HumanMessage
                    
                    # Get LLM decision
                    response = self.reasoning_llm.invoke([HumanMessage(content=decision_prompt)])
                    decision_text = response.content.strip().lower()
                    
                    # Parse the LLM response with better logic
                    if search_count == 0:
                        # Force search if none done yet
                        enhanced_query = self._enhance_search_query(query)
                        return {
                            "action": "search_intelligence",
                            "args": {"query": enhanced_query},
                            "reasoning": f"Groq LLM decision: Initial search for '{enhanced_query}'"
                        }
                    elif search_count > 0 and summarize_count == 0:
                        # Force summarize if search done but no summary
                        return {
                            "action": "summarize_content", 
                            "reasoning": "Groq LLM decision: Search completed - need to summarize results"
                        }
                    elif summarize_count > 0 and verify_count == 0:
                        # Force verify if summary done but no verification
                        return {
                            "action": "verify_updates",
                            "reasoning": "Groq LLM decision: Summarization completed - need to verify updates"
                        }
                    else:
                        # All steps done
                        return {
                            "action": "complete",
                            "reasoning": "Groq LLM decision: All ReAct steps completed successfully"
                        }
                        
                except Exception as e:
                    print(f"‚ö†Ô∏è Groq LLM decision failed: {e}, falling back to rule-based")
            
            # Fallback to rule-based decision making
            search_count = step_counter.get("search", 0)
            summarize_count = step_counter.get("summarize", 0) 
            verify_count = step_counter.get("verify", 0)
            
            # Intelligent workflow progression
            if search_count == 0:
                # Need to search first
                enhanced_query = self._enhance_search_query(query)
                return {
                    "action": "search_intelligence",
                    "args": {"query": enhanced_query},
                    "reasoning": f"Product query detected - need to search for '{enhanced_query}'"
                }
            elif search_count > 0 and summarize_count == 0:
                return {
                    "action": "summarize_content", 
                    "reasoning": "Search completed - need to summarize results"
                }
            elif summarize_count > 0 and verify_count == 0:
                return {
                    "action": "verify_updates",
                    "reasoning": "Summarization completed - need to verify updates"
                }
            else:
                return {
                    "action": "complete",
                    "reasoning": "All ReAct steps completed successfully"
                }
                
        except Exception as e:
            return {
                "action": "search_intelligence",
                "args": {"query": query},
                "reasoning": f"Error in decision making: {e} - defaulting to search"
            }
    
    def _enhance_search_query(self, query: str) -> str:
        """Enhance queries for better search results"""
        query = query.lower().strip()
        
        # Add context for better search results
        if len(query.split()) == 1:
            return f"{query} latest news updates 2025"
        else:
            return f"{query} latest updates 2025"

    def _reason_next_action(self, query: str, step_counter: dict, messages: list) -> dict:
        """Use HF model or rules to determine next action in ReAct workflow."""
        try:
            # Create reasoning prompt
            context = f"""
            Query: {query}
            Steps completed: {step_counter}
            
            Available actions:
            1. search_intelligence - Search for information about the query
            2. summarize_content - Summarize search results into product updates
            3. verify_updates - Verify and filter the summarized updates
            
            Based on the query and completed steps, what should be the next action?
            If search=0, we need to search first.
            If search>0 and summarize=0, we need to summarize.
            If search>0 and summarize>0 and verify=0, we need to verify.
            If all steps completed, respond with 'complete'.
            
            Next action:"""
            
            if self.llm:
                try:
                    # Use HF model for reasoning
                    response = self.llm(context, max_length=len(context) + 50)
                    reasoning = response[0]['generated_text'][len(context):].strip()
                    
                    if "search" in reasoning.lower():
                        return {"action": "search", "reasoning": reasoning}
                    elif "summarize" in reasoning.lower():
                        return {"action": "summarize", "reasoning": reasoning}
                    elif "verify" in reasoning.lower():
                        return {"action": "verify", "reasoning": reasoning}
                    else:
                        return {"action": "complete", "reasoning": reasoning}
                        
                except Exception as e:
                    print(f"HF reasoning failed: {e}, using fallback")
            
            # Fallback to rule-based reasoning
            if step_counter["search"] == 0:
                return {"action": "search", "reasoning": "Need to search for information first"}
            elif step_counter["search"] > 0 and step_counter["summarize"] == 0:
                return {"action": "summarize", "reasoning": "Need to summarize search results"}
            elif step_counter["search"] > 0 and step_counter["summarize"] > 0 and step_counter["verify"] == 0:
                return {"action": "verify", "reasoning": "Need to verify summarized updates"}
            else:
                return {"action": "complete", "reasoning": "All steps completed"}
                
        except Exception as e:
            return {"action": "search", "reasoning": f"Error in reasoning: {e}"}
    
    def _create_tools(self):
        """Create tools for the LangGraph coordinator."""
        
        @tool
        def search_intelligence(query: str) -> str:
            """Search for competitive intelligence using SearchAgent."""
            try:
                print(f"üîç Searching for: '{query}'")
                
                # Use the search agent directly with the query
                search_results = self.search_agent.search(query, max_results=5)
                
                if not search_results:
                    # Try with more general search terms if no results
                    fallback_query = f"{query} news updates technology"
                    print(f"üîÑ Trying fallback: '{fallback_query}'")
                    search_results = self.search_agent.search(fallback_query, max_results=3)
                
                if not search_results:
                    return json.dumps({"status": "no_results", "message": "No search results found"})
                
                results_data = []
                for result in search_results:
                    results_data.append({
                        "url": result.url,
                        "title": result.title,
                        "content": result.snippet[:500],  # Use snippet instead of content
                        "domain": result.source  # Use source instead of domain
                    })
                
                return json.dumps({
                    "status": "success",
                    "results_count": len(search_results),
                    "results": results_data,
                    "query_used": query
                })
                
            except Exception as e:
                return json.dumps({"status": "error", "message": str(e)})
        
        @tool  
        def summarize_content(content: str) -> str:
            """Summarize content using SummarizerAgent."""
            try:
                # Handle both direct content and search results JSON
                content_to_summarize = content
                product_name = "Unknown"
                
                # If it's JSON from search results, use the appropriate method
                try:
                    search_data = json.loads(content)
                    if search_data.get("status") == "success" and "results" in search_data:
                        # Use the JSON method of summarizer
                        summary_updates = self.summarizer_agent.summarize_from_json(content, "product_update")
                        
                        if not summary_updates:
                            return json.dumps({"status": "error", "message": "Failed to generate summary"})
                        
                        # Convert ProductUpdate objects to dict format
                        updates = []
                        for update in summary_updates:
                            updates.append({
                                "product": update.product,
                                "update": update.update,
                                "source": update.source,
                                "date": update.date,
                                "confidence_score": update.confidence_score,
                                "relevance_score": update.relevance_score
                            })
                        
                        return json.dumps({
                            "status": "success",
                            "updates": updates
                        })
                except json.JSONDecodeError:
                    # If not JSON, use direct text summarization method
                    pass
                
                # Fallback to basic text processing
                summary = self.summarizer_agent.summarize(content_to_summarize, "product_update")
                
                if not summary:
                    return json.dumps({"status": "error", "message": "Failed to generate summary"})
                
                # Format summary for further processing
                summary_text = summary[0] if isinstance(summary, list) else str(summary)
                
                # Create updates in the expected format
                updates = [{
                    "product": "Unknown",
                    "update": summary_text,
                    "source": "Multiple sources",
                    "date": datetime.now().strftime("%Y-%m-%d"),
                    "confidence_score": 0.8,
                    "relevance_score": 0.9
                }]
                
                return json.dumps({
                    "status": "success",
                    "updates": updates
                })
                
            except Exception as e:
                return json.dumps({"status": "error", "message": str(e)})
        
        @tool
        def verify_updates(updates_json: str) -> str:
            """Verify updates using VerifierAgent."""
            try:
                # Remove print statements for clean output
                
                # Parse updates
                updates_data = json.loads(updates_json)
                if updates_data.get("status") != "success":
                    return json.dumps({"status": "error", "message": "Invalid updates data"})
                
                # Handle updates format from summarizer
                updates_list = updates_data.get("updates", [])
                if not updates_list:
                    return json.dumps({"status": "error", "message": "No updates to verify"})
                
                # Convert to ProductUpdate objects for verification
                from models import ProductUpdate
                updates = []
                for update_data in updates_list:
                    updates.append(ProductUpdate(
                        product=update_data.get("product", "Unknown"),
                        update=update_data.get("update", "No update"),
                        source=update_data.get("source", "Unknown"),
                        date=update_data.get("date", datetime.now().strftime("%Y-%m-%d")),
                        confidence_score=update_data.get("confidence_score", 0.8),
                        relevance_score=update_data.get("relevance_score", 0.9)
                    ))
                
                # Verify using the verifier agent
                verified_updates = self.verifier_agent.verify(updates)
                
                verified_data = []
                for update in verified_updates:
                    # Format in the requested structured JSON format
                    structured_update = {
                        "product": update.product,
                        "update": update.update, 
                        "source": update.source,
                        "date": update.date
                    }
                    verified_data.append(structured_update)
                
                # Remove print statements for clean output
                return json.dumps({
                    "status": "success",
                    "verified_count": len(verified_updates),
                    "verified_updates": verified_data,
                    "format": "structured_json"
                })
                
            except Exception as e:
                return json.dumps({"status": "error", "message": str(e)})
        
        @tool
        def recall_memory(thread_id: str) -> str:
            """Recall previous analysis from in-memory storage."""
            try:
                if thread_id in self.conversation_history:
                    return json.dumps(self.conversation_history[thread_id])
                else:
                    return json.dumps({"status": "no_memory", "message": "No memory found"})
            except Exception as e:
                return json.dumps({"status": "error", "message": str(e)})
        
        return [search_intelligence, summarize_content, verify_updates, recall_memory]
    
    def _format_structured_output(self, updates_list: list) -> list:
        """Format updates into the structured JSON format requested by user."""
        structured_updates = []
        for update in updates_list:
            structured_update = {
                "product": update.get("product", "Unknown"),
                "update": update.get("update", "No update information"),
                "source": update.get("source", "Unknown source"),
                "date": update.get("date", datetime.now().strftime("%Y-%m-%d"))
            }
            structured_updates.append(structured_update)
        return structured_updates
    
    def _format_analysis_result(self, report) -> str:
        """Format analysis result for tools."""
        if not report.updates:
            return json.dumps({
                "query": report.query,
                "category": report.category,
                "updates": [],
                "message": "No updates found"
            })
        
        result = {
            "query": report.query,
            "category": report.category,
            "processing_time": round(report.processing_time, 2),
            "total_sources": report.total_sources,
            "updates": []
        }
        
        for update in report.updates:
            result["updates"].append({
                "product": update.product,
                "update": update.update,
                "source": update.source,
                "date": update.date,
                "confidence_score": round(update.confidence_score, 2),
                "relevance_score": round(update.relevance_score, 2)
            })
        
        return json.dumps(result, indent=2)
    
    def _create_graph(self) -> StateGraph:
        """Create the LangGraph ReAct workflow for coordination."""
        
        def should_continue(state: AgentState) -> str:
            """Determine if the agent should continue or end."""
            messages = state["messages"]
            last_message = messages[-1]
            
            if isinstance(last_message, AIMessage) and not last_message.tool_calls:
                return "end"
            return "continue"
        
        def call_coordinator(state: AgentState) -> dict:
            """Coordinate the analysis using intelligent ReAct decision making."""
            messages = state["messages"]
            query = state["query"]
            step_counter = state.get("step_counter", {"search": 0, "summarize": 0, "verify": 0})
            
            print(f"üîÑ Step counter: {step_counter}")
            
            # Use intelligent decision making with prompt templates
            decision = self._make_intelligent_decision(query, step_counter)
            action = decision["action"]
            reasoning = decision["reasoning"]
            
            print(f"üß† ReAct Decision: {reasoning}")
            
            # Prevent infinite loops - limit each tool to 2 executions per query
            if step_counter["search"] >= 2 and step_counter["summarize"] >= 2 and step_counter["verify"] >= 2:
                response = AIMessage(
                    content="üéâ Analysis complete! I've thoroughly searched, summarized, and verified the results using ReAct reasoning.",
                    tool_calls=[]
                )
                return {"messages": [response]}
            
            # Execute the determined action
            if action == "respond_directly":
                # Direct response for greetings/casual queries
                response = AIMessage(
                    content=decision["response"],
                    tool_calls=[]
                )
                return {"messages": [response]}
            
            elif action == "search_intelligence":
                # Search action with enhanced query
                search_query = decision.get("args", {}).get("query", query)
                response = AIMessage(
                    content=f"üîç ReAct Agent: Searching for '{search_query}' using DuckDuckGo and web scraping tools.",
                    tool_calls=[{
                        "name": "search_intelligence",
                        "args": {"query": search_query},
                        "id": f"search_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    }]
                )
            
            elif action == "summarize_content":
                # Get the last search results from messages
                search_result = None
                tool_messages = [msg for msg in messages if isinstance(msg, ToolMessage)]
                for msg in reversed(tool_messages):
                    if msg.name == "search_intelligence":
                        search_result = msg.content
                        break
                
                if search_result:
                    response = AIMessage(
                        content="üìù ReAct Agent: Using HuggingFace models to extract and summarize product updates.",
                        tool_calls=[{
                            "name": "summarize_content",
                            "args": {"content": search_result},
                            "id": f"summarize_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                        }]
                    )
                else:
                    response = AIMessage(content="‚ùå ReAct Agent: No search results found for summarization.")
            
            elif action == "verify_updates":
                # Get the last summarization results from messages
                summary_result = None
                tool_messages = [msg for msg in messages if isinstance(msg, ToolMessage)]
                for msg in reversed(tool_messages):
                    if msg.name == "summarize_content":
                        summary_result = msg.content
                        break
                
                if summary_result:
                    response = AIMessage(
                        content="‚úÖ ReAct Agent: Verifying updates for quality, reliability, and accuracy.",
                        tool_calls=[{
                            "name": "verify_updates",
                            "args": {"updates_json": summary_result},
                            "id": f"verify_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                        }]
                    )
                else:
                    response = AIMessage(content="‚ùå ReAct Agent: No summary results found for verification.")
            
            else:  # action == "complete"
                response = AIMessage(
                    content="üéâ ReAct Agent: Analysis workflow completed successfully!",
                    tool_calls=[]
                )
            
            return {"messages": [response]}
        
        def call_tools(state: AgentState) -> dict:
            """Execute tools for search, summarization, and verification."""
            messages = state["messages"]
            last_message = messages[-1]
            step_counter = state.get("step_counter", {"search": 0, "summarize": 0, "verify": 0})
            
            tool_messages = []
            if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
                for tool_call in last_message.tool_calls:
                    tool_name = tool_call["name"]
                    tool_args = tool_call["args"]
                    tool_id = tool_call["id"]
                    
                    # Execute the appropriate tool
                    for tool in self.tools:
                        if tool.name == tool_name:
                            try:
                                result = tool.func(**tool_args)
                                tool_messages.append(
                                    ToolMessage(
                                        content=str(result),
                                        tool_call_id=tool_id,
                                        name=tool_name
                                    )
                                )
                                
                                # Increment step counter
                                if tool_name == "search_intelligence":
                                    step_counter["search"] += 1
                                elif tool_name == "summarize_content":
                                    step_counter["summarize"] += 1
                                elif tool_name == "verify_updates":
                                    step_counter["verify"] += 1
                                    
                            except Exception as e:
                                tool_messages.append(
                                    ToolMessage(
                                        content=json.dumps({"status": "error", "message": str(e)}),
                                        tool_call_id=tool_id,
                                        name=tool_name
                                    )
                                )
                            break
            
            return {"messages": tool_messages, "step_counter": step_counter}
        
        # Create the workflow graph
        workflow = StateGraph(AgentState)
        
        # Add nodes
        workflow.add_node("coordinator", call_coordinator)
        workflow.add_node("tools", call_tools)
        
        # Set entry point
        workflow.set_entry_point("coordinator")
        
        # Add conditional edges
        workflow.add_conditional_edges(
            "coordinator",
            should_continue,
            {
                "continue": "tools",
                "end": END
            }
        )
        
        # Add edge from tools back to coordinator
        workflow.add_edge("tools", "coordinator")
        
        # Compile the workflow (no recursion_limit parameter)
        return workflow.compile()
    
    def _format_messages(self, messages: list) -> str:
        """Format messages for display."""
        formatted = []
        for msg in messages:
            if isinstance(msg, HumanMessage):
                formatted.append(f"Human: {msg.content}")
            elif isinstance(msg, AIMessage):
                formatted.append(f"AI: {msg.content}")
            elif isinstance(msg, ToolMessage):
                formatted.append(f"Tool ({msg.name}): {msg.content[:200]}...")
        return "\n".join(formatted)
    
    async def stream_analysis(self, query: str, thread_id: str = None) -> AsyncGenerator[dict, None]:
        """Stream analysis results with in-memory storage."""
        if not thread_id:
            thread_id = f"thread_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        config = {"configurable": {"thread_id": thread_id}}
        
        initial_state = {
            "messages": [HumanMessage(content=query)],
            "query": query,
            "results": {},
            "memory_key": thread_id,
            "thread_id": thread_id,
            "stream_data": []
        }
        
        try:
            async for chunk in self.graph.astream(initial_state, config=config):
                # Format streaming data
                stream_chunk = {
                    "timestamp": datetime.now().isoformat(),
                    "thread_id": thread_id,
                    "chunk": chunk,
                    "type": "update"
                }
                
                yield stream_chunk
                
                # Add small delay for demonstration
                await asyncio.sleep(0.1)
                
        except Exception as e:
            yield {
                "timestamp": datetime.now().isoformat(),
                "thread_id": thread_id,
                "error": str(e),
                "type": "error"
            }
    
    async def get_clean_analysis(self, query: str, thread_id: Optional[str] = None) -> AsyncGenerator[str, None]:
        """
        Get only the final JSON results without intermediate steps.
        """
        try:
            # Input validation with Simple Guardrails
            if self.use_guardrails:
                if not self.guardrails.validate_query(query):
                    yield f"‚ùå **Input validation failed**: Query contains inappropriate content or is too long\n\n"
                    return
            
            if not thread_id:
                thread_id = f"thread_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # Initialize state
            initial_state = {
                "messages": [HumanMessage(content=query)],
                "query": query,
                "thread_id": thread_id,
                "step_counter": {"search": 0, "summarize": 0, "verify": 0}
            }
            
            config = {"configurable": {"thread_id": thread_id}}
            
            # Run the workflow silently and only return final results
            async for output in self.graph.astream(initial_state, config):
                for node_name, node_output in output.items():
                    if "messages" in node_output:
                        for message in node_output["messages"]:
                            # Only show final JSON results from verification
                            if isinstance(message, ToolMessage):
                                try:
                                    result_data = json.loads(message.content)
                                    
                                    # Only output verified updates in JSON format
                                    if message.name == "verify_updates" and "verified_updates" in result_data:
                                        for update in result_data["verified_updates"]:
                                            # Extract concise update title
                                            update_text = update["update"]
                                            if "." in update_text:
                                                concise_update = update_text.split(".")[0] + "."
                                            else:
                                                concise_update = update_text[:100] + "..." if len(update_text) > 100 else update_text
                                            
                                            # Use the date that was already extracted by the summarizer agent
                                            extracted_date = update.get("date", "none")
                                            
                                            structured_output = {
                                                "product": f"{update['product']}",
                                                "update": concise_update,
                                                "source": update["source"],
                                                "date": extracted_date
                                            }
                                            yield f"{json.dumps(structured_output, indent=2)}\n\n"
                                except json.JSONDecodeError:
                                    pass
                            
        except Exception as e:
            yield f"‚ùå **Error**: {str(e)}\n\n"
        """
        Coordinate competitive intelligence analysis using LangGraph ReAct workflow.
        """
        try:
            if not thread_id:
                thread_id = f"thread_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # Initialize state
            initial_state = {
                "messages": [HumanMessage(content=query)],
                "query": query,
                "thread_id": thread_id,
                "step_counter": {"search": 0, "summarize": 0, "verify": 0}
            }
            
            config = {"configurable": {"thread_id": thread_id}}
            
            # Stream the workflow execution
            async for output in self.graph.astream(initial_state, config):
                for node_name, node_output in output.items():
                    if "messages" in node_output:
                        for message in node_output["messages"]:
                            # Only show final JSON results from verification
                            if isinstance(message, ToolMessage):
                                try:
                                    result_data = json.loads(message.content)
                                    
                                    # Only output verified updates in JSON format  
                                    if message.name == "verify_updates" and "verified_updates" in result_data:
                                        for update in result_data["verified_updates"]:
                                            # Extract concise update title from the full update text
                                            update_text = update["update"]
                                            if "." in update_text:
                                                # Take the first sentence as the concise update
                                                concise_update = update_text.split(".")[0] + "."
                                            else:
                                                concise_update = update_text[:100] + "..." if len(update_text) > 100 else update_text
                                            
                                            # Extract actual date from the content if available
                                            import re
                                            date_patterns = [
                                                r'(\d{1,2}\s+days?\s+ago)',
                                                r'(\d{1,2}\s+hours?\s+ago)', 
                                                r'(January|February|March|April|May|June|July|August|September|October|November|December)\s+(\d{1,2},?\s+\d{4})',
                                                r'(\d{4}-\d{2}-\d{2})'
                                            ]
                                            
                                            extracted_date = "2025-07-25"  # Default to today
                                            for pattern in date_patterns:
                                                match = re.search(pattern, update_text, re.IGNORECASE)
                                                if match:
                                                    if "ago" in match.group(0):
                                                        extracted_date = "2025-07-25"  # Recent update
                                                    else:
                                                        extracted_date = match.group(0)
                                                    break
                                            
                                            structured_output = {
                                                "product": f"{update['product']}",
                                                "update": concise_update,
                                                "source": update["source"],
                                                "date": extracted_date
                                            }
                                            yield f"{json.dumps(structured_output, indent=2)}\n\n"
                                    
                                    # Format other tool outputs
                                    elif "results" in result_data:
                                        yield f"ÔøΩ **{message.name} Results**:\n{json.dumps(result_data['results'], indent=2)}\n\n"
                                    elif "updates" in result_data:
                                        yield f"üìù **{message.name} Updates**:\n{json.dumps(result_data['updates'], indent=2)}\n\n"
                                    else:
                                        yield f"üìã **{message.name} Output**:\n{message.content}\n\n"
                                except json.JSONDecodeError:
                                    yield f"üìã **{message.name} Output**:\n{message.content}\n\n"
                        
                        await asyncio.sleep(0.1)  # Allow UI updates
            
        except Exception as e:
            yield f"‚ùå **Error in LangGraph coordination**: {str(e)}\n\n"
    
    async def get_clean_analysis(self, query: str, thread_id: Optional[str] = None) -> AsyncGenerator[str, None]:
        """
        Get clean analysis results with only JSON output - no intermediate steps.
        """
        try:
            if not thread_id:
                thread_id = f"thread_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # Initialize state
            initial_state = {
                "messages": [HumanMessage(content=query)],
                "query": query,
                "thread_id": thread_id,
                "step_counter": {"search": 0, "summarize": 0, "verify": 0}
            }
            
            config = {"configurable": {"thread_id": thread_id}}
            
            # Handle greetings
            casual_greetings = ["hi", "hello", "hey", "greetings", "good morning", "good afternoon", "good evening"]
            if query.lower().strip() in casual_greetings:
                yield "üëã Hello! I'm your LangGraph Coordinator Agent. I can help you analyze competitive intelligence, search for product updates, and provide structured insights. Try asking me something like:\n\n‚Ä¢ 'What are the latest ChatGPT features?'\n‚Ä¢ 'Tell me about Tesla's new updates'\n‚Ä¢ 'Analyze GitHub Copilot improvements'\n\nWhat would you like to analyze today?"
                return
            
            # Run the workflow silently and collect results
            final_updates = []
            async for output in self.graph.astream(initial_state, config):
                for node_name, node_output in output.items():
                    if "messages" in node_output:
                        for message in node_output["messages"]:
                            if isinstance(message, ToolMessage) and message.name == "verify_updates":
                                try:
                                    result_data = json.loads(message.content)
                                    if "verified_updates" in result_data:
                                        final_updates = result_data["verified_updates"]
                                        break
                                except:
                                    pass
            
            # Output only the clean JSON results
            for update in final_updates:
                # Extract concise update title
                update_text = update["update"]
                if "." in update_text:
                    concise_update = update_text.split(".")[0] + "."
                else:
                    concise_update = update_text[:100] + "..." if len(update_text) > 100 else update_text
                
                # Extract date
                import re
                date_patterns = [
                    r'(\d{1,2}\s+days?\s+ago)',
                    r'(\d{1,2}\s+hours?\s+ago)', 
                    r'(January|February|March|April|May|June|July|August|September|October|November|December)\s+(\d{1,2},?\s+\d{4})',
                    r'(\d{4}-\d{2}-\d{2})'
                ]
                
                extracted_date = "2025-07-25"  # Default to today
                for pattern in date_patterns:
                    match = re.search(pattern, update_text, re.IGNORECASE)
                    if match:
                        if "ago" in match.group(0):
                            extracted_date = "2025-07-25"
                        else:
                            extracted_date = match.group(0)
                        break
                
                structured_output = {
                    "product": update['product'],
                    "update": concise_update,
                    "source": update["source"],
                    "date": extracted_date
                }
                yield f"{json.dumps(structured_output, indent=2)}\n\n"
            
        except Exception as e:
            yield f"‚ùå **Error**: {str(e)}\n\n"
    
    def analyze_sync(self, query: str, thread_id: str = None) -> dict:
        """Synchronous analysis with in-memory storage."""
        if not thread_id:
            thread_id = f"thread_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        config = {"configurable": {"thread_id": thread_id}}
        
        initial_state = {
            "messages": [HumanMessage(content=query)],
            "query": query,
            "results": {},
            "memory_key": thread_id,
            "thread_id": thread_id,
            "stream_data": []
        }
        
        try:
            result = self.graph.invoke(initial_state, config=config)
            
            return {
                "thread_id": thread_id,
                "query": query,
                "result": result,
                "timestamp": datetime.now().isoformat(),
                "status": "completed"
            }
            
        except Exception as e:
            return {
                "thread_id": thread_id,
                "query": query,
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "status": "failed"
            }
    
    def get_memory_threads(self) -> list:
        """Get all memory threads from in-memory storage."""
        try:
            # Return threads sorted by most recent
            threads = list(self.conversation_history.keys())
            # Sort by timestamp if available
            def get_timestamp(thread_id):
                return self.conversation_history.get(thread_id, {}).get('timestamp', '0')
            
            threads.sort(key=get_timestamp, reverse=True)
            return threads
        except Exception:
            return []
    
    def continue_conversation(self, thread_id: str, new_message: str) -> dict:
        """Continue a conversation from in-memory state."""
        config = {"configurable": {"thread_id": thread_id}}
        
        # Initialize basic state for new message
        initial_state = {
            "messages": [HumanMessage(content=new_message)],
            "query": new_message,
            "results": {},
            "memory_key": thread_id,
            "thread_id": thread_id,
            "stream_data": []
        }
        
        try:
            result = self.graph.invoke(initial_state, config=config)
            return {
                "thread_id": thread_id,
                "query": new_message,
                "result": result,
                "timestamp": datetime.now().isoformat(),
                "status": "continued"
            }
        except Exception as e:
            return {
                "thread_id": thread_id,
                "query": new_message,
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "status": "failed"
            }
    
    async def analyze_with_a2a_protocol(self, query: str) -> dict:
        """Perform analysis using A2A protocol for agent communication."""
        if not self.use_a2a:
            print("‚ö†Ô∏è A2A protocol not enabled")
            return {}
        
        try:
            correlation_id = f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
            
            # Start A2A protocol
            protocol_task = asyncio.create_task(self.a2a_protocol.start())
            await asyncio.sleep(0.1)  # Let protocol start
            
            # Step 1: Send search request via A2A
            search_message = A2AMessage(
                id=f"search_request_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}",
                type=MessageType.REQUEST,
                sender=AgentRole.COORDINATOR,
                receiver=AgentRole.SEARCH,
                payload={"query": query},
                timestamp=datetime.now().isoformat(),
                correlation_id=correlation_id
            )
            
            print(f"üîç Sending A2A search request for: {query}")
            await self.a2a_protocol.send_message(search_message)
            
            # Wait for search response
            await asyncio.sleep(2)
            
            # Check if we have search results
            if hasattr(self, 'a2a_responses') and correlation_id in self.a2a_responses:
                search_results = self.a2a_responses[correlation_id].get('search', {}).get('results', [])
                
                if search_results:
                    # Step 2: Send summarizer request
                    summarizer_message = A2AMessage(
                        id=f"summarizer_request_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}",
                        type=MessageType.REQUEST,
                        sender=AgentRole.COORDINATOR,
                        receiver=AgentRole.SUMMARIZER,
                        payload={"search_results": search_results},
                        timestamp=datetime.now().isoformat(),
                        correlation_id=correlation_id
                    )
                    
                    print(f"üìù Sending A2A summarizer request")
                    await self.a2a_protocol.send_message(summarizer_message)
                    await asyncio.sleep(2)
                    
                    # Step 3: Send verifier request
                    updates = self.a2a_responses[correlation_id].get('summarizer', {}).get('updates', [])
                    if updates:
                        verifier_message = A2AMessage(
                            id=f"verifier_request_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}",
                            type=MessageType.REQUEST,
                            sender=AgentRole.COORDINATOR,
                            receiver=AgentRole.VERIFIER,
                            payload={"updates": updates},
                            timestamp=datetime.now().isoformat(),
                            correlation_id=correlation_id
                        )
                        
                        print(f"‚úÖ Sending A2A verifier request")
                        await self.a2a_protocol.send_message(verifier_message)
                        await asyncio.sleep(2)
            
            # Stop protocol
            self.a2a_protocol.stop()
            protocol_task.cancel()
            
            # Return results
            final_results = self.a2a_responses.get(correlation_id, {})
            verified_updates = final_results.get('verifier', {}).get('verified_updates', [])
            
            return {
                "query": query,
                "verified_updates": verified_updates,
                "workflow": "A2A Protocol",
                "correlation_id": correlation_id
            }
            
        except Exception as e:
            print(f"‚ùå A2A analysis failed: {e}")
            return {"error": str(e), "query": query}

    def get_simple_analysis_with_a2a(self, query: str) -> str:
        """Get analysis result using A2A protocol for agent communication."""
        try:
            # Use A2A protocol for agent communication
            import asyncio
            
            async def run_a2a_analysis():
                return await self.analyze_with_a2a_protocol(query)
            
            # Run A2A analysis
            result = asyncio.run(run_a2a_analysis())
            
            # Format result as clean JSON
            if "verified_updates" in result and result["verified_updates"]:
                first_update = result["verified_updates"][0]
                clean_result = {
                    "product": first_update.get("product", query.split()[0] if query.split() else "Unknown"),
                    "update": first_update.get("update", "No update available"),
                    "source": first_update.get("source", "Unknown source"),
                    "date": first_update.get("date", datetime.now().strftime("%Y-%m-%d"))
                }
                return json.dumps(clean_result, indent=2)
            else:
                # Fallback to regular analysis
                return self.get_simple_analysis(query)
                
        except Exception as e:
            print(f"‚ùå A2A analysis failed, falling back to regular analysis: {e}")
            return self.get_simple_analysis(query)

    def get_simple_analysis(self, query: str) -> str:
        """Get analysis result using the full LangGraph ReAct coordinator."""
        try:
            # Use the actual LangGraph coordinator to reason and act
            thread_id = f"simple_{hash(query)}_{datetime.now().strftime('%H%M%S')}"
            
            # Initialize state for LangGraph workflow
            initial_state = {
                "messages": [HumanMessage(content=query)],
                "query": query,
                "thread_id": thread_id,
                "step_counter": {"search": 0, "summarize": 0, "verify": 0}
            }
            
            config = {"configurable": {"thread_id": thread_id}}
            
            # Run the full LangGraph ReAct workflow and collect all messages
            verified_updates = []
            all_messages = []
            
            # Use astream to capture all intermediate results
            import asyncio
            
            async def run_workflow():
                nonlocal verified_updates, all_messages
                async for step_output in self.graph.astream(initial_state, config):
                    for node_name, node_output in step_output.items():
                        if "messages" in node_output:
                            all_messages.extend(node_output["messages"])
                            
                            # Look for direct responses from coordinator (greetings, introductions, etc.)
                            for message in node_output["messages"]:
                                if isinstance(message, AIMessage) and (not hasattr(message, 'tool_calls') or not message.tool_calls):
                                    # Check if this is a direct response (greeting, introduction, etc.)
                                    if any(keyword in message.content for keyword in ["Hello!", "Nice to meet you", "ReAct Agent powered by Groq"]):
                                        # Return direct response as special JSON format
                                        verified_updates = [{
                                            "product": "ReAct Agent",
                                            "update": message.content,
                                            "source": "LangGraph ReAct Coordinator", 
                                            "date": datetime.now().strftime("%Y-%m-%d")
                                        }]
                                        return
                                        
                                # Look for verification results (capture immediately when they appear)
                                elif isinstance(message, ToolMessage) and message.name == "verify_updates":
                                    try:
                                        result_data = json.loads(message.content)
                                        if "verified_updates" in result_data and result_data["verified_updates"]:
                                            verified_updates = result_data["verified_updates"]
                                            # Return immediately after getting verification results
                                            return
                                    except Exception as e:
                                        print(f"‚ö†Ô∏è Error parsing verification results: {e}")
                                        pass
            
            # Run the async workflow
            asyncio.run(run_workflow())
            
            # Format the first verified update as clean JSON
            if verified_updates:
                first_update = verified_updates[0]
                clean_result = {
                    "product": first_update.get("product", query.split()[0] if query.split() else "Unknown"),
                    "update": first_update.get("update", "No update available"),
                    "source": first_update.get("source", "Unknown source"),
                    "date": first_update.get("date", datetime.now().strftime("%Y-%m-%d"))
                }
                return json.dumps(clean_result, indent=2)
            
            # If no verified updates, fallback to error message
            return json.dumps({
                "product": query.split()[0] if query.split() else "Unknown",
                "update": "Unable to retrieve verified updates through ReAct workflow",
                "source": "LangGraph ReAct Coordinator",
                "date": datetime.now().strftime("%Y-%m-%d")
            }, indent=2)
            
        except Exception as e:
            return json.dumps({
                "product": query.split()[0] if query.split() else "Unknown", 
                "update": f"ReAct workflow error: {str(e)[:100]}",
                "source": "Error in LangGraph coordination",
                "date": datetime.now().strftime("%Y-%m-%d")
            }, indent=2)
